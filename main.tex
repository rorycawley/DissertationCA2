%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex
%%*************************************************************************

% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[final,a4paper,peerreviewca]{IEEEtran}
%\documentclass[10pt,technote]{IEEEtran} 
\usepackage{blindtext}
\usepackage{graphicx}
\usepackage{natbib}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Comparing Deep Learning based Methods for Analyzing Customer Churn in the Software as a Service (SaaS) Industry}

\author{Rory~Cawley,~rory.cawley@gmail.com,~x00142235
        % <-this % stops a space
}

% The paper headers
\markboth{Research Methods CA2, M.Sc. in IT Architecture, ITT, December~2017}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Journals}

% make the title area
\maketitle

\begin{abstract}
%\boldmath
Customer churn is loosely defined as the loss of a customer because they move to a competitor. It’s an expensive problem since the cost of retaining a customer is a fraction of the cost to acquire a new customer. Predicting customer churn is a business classic problem that can be addressed with data analysis of customer behavior, product usage and purchasing patterns. The accurate and early identification of customers at risk of churning is important for minimizing the cost and impact of the company's retention marketing strategy. Tackling churn effectively could also mean the difference between business success and failure. This paper reviews the current state of the art and suggests some potential improvements.
\end{abstract}


\begin{IEEEkeywords}
Churn Prediction, SaaS, Neural Networks, Deep Learning, RNN, Survival Analysis
\end{IEEEkeywords}

% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\section{Introduction}
Software as a Service (SaaS) is a software licensing and deployment model in which customers subscribe to a license to access a software product that is hosted centrally. The subscription are sold for a fixed period of time, often monthly or annually. This method of software purchasing has many advantages for the customer including short time to realise value from using the software due to lack of software installation and minimum configuration. The customer can also decide to move to a competitor without much impact other than the repatriation of their data from their existing system to the new system. This dependency on the customer to constantly renew their commitment to pay for the software subscription makes the vendor focus their efforts on customer satisfaction and retention.

When a customer stops being a customer it can be for a number of reasons so the identification of those reasons is important. A customer can churn for incidental reasons unrelated to the service they buy. Examples of incidental churn are relocation of the business or failure of the business. Deliberate churn is what we seek to predict and that is only when a customer makes the decision to move to a competitor. The reasons behind this need to be identified for the purposes of taking action to improve the business. Examples of these reasons are poor product offering relative to competing products, poor customer service via call centers or even higher prices than competitors.

Survival analysis is an analysis method made up of three components: events, censoring and time-based prediction. Events are occurrences of note, for churn prediction they are often a login or a transaction, equally it could be a negative event such as cancellation of an account. Censoring is when we have information but it is incomplete, in survival analysis censored information is included in the analysis so more information and more recent information can be used. Right censoring is used when we know that an event has not occurred up to a certain point in time. Since all customers will churn at some point rather than run a classification to decide whether a customer is a churner or not it's more useful to use survival analysis to view non-churners in right-censored data i.e. they have not churned yet but will at some point. The quantity most of interest is time to event rather than whether an event occurred or not. This allows the estimation future customer lifetime value, which is important for ranking in order to prioritize churn prevention efforts. For these reasons survival analysis is well suited to the application of customer churn prediction.

An Artificial Neural Network (ANN) is a type of algorithm that seeks to identify underlying patterns in a set of data. Neural networks can to adapt to changing input to produce accurate results without the need to redesign the output criteria. Recurrent Neural Networks (RNNs) have a distinguishing feature from other types of neural networks in that they have a feedback loop. This means that for each time step, the recurrent neuron receives the output from the previous step as well as the normal input. This means the neuron has some memory of previous states, which it can take into consideration. RNNs perform the same computations for all data items in a sequence of inputs. They are used to analysis sequences of data such as speech, sound, stock prices and are able to forecast data such as this that is in a never ending sequence. Survival analysis works on sequences of time series data so it's a good match for use with RNNs.

Efforts to predict churn start off with the identification of the determinants of churn and then proceed to the prediction of likely churners. The identified potential churners can then be ranked in importance to the business in order to direct targeted campaigns to discourage the potential churn. Marketing efforts targeting high ranked potential churners would then have a better return for the business.

\subsection{Background}
With traditional on-premise installed software the vendor has no intelligence on how the customer uses the software or even if they use it at all. The vendor may also roll out new features in the hope that they will be popular with the client but they will not have a way of measuring the impact of that product development investment. On the other hand, SaaS products are able to gather the usage information on the product users. Questions such as "When did they login and logoff?" or "What features are most used and least used?" cannot be answered. This product usage information is vital for product development but it's also a useful indicator to predict customer churn.

Customer churn is a well studied area for general businesses and in the last few years has been a commonly studied area for SaaS businesses. Churn analysis is used to attempt to answer questions such as "Why are customers churning?", "Can we predict what customers will churn and possibly change their mind so they stay?" and "How long do customers to stay with us?". Another important set of related question are: "What is the customer lifetime value?" and "Who are our most valuable customers?". 

Since it's clear that at some stage every customer will eventually churn then having a model such as a binary classifier provide prediction that each customer will churn isn't useful. The salient information is to know when a churn event is likely to happen soon so that scarce company resources might be directed to take action to prevent the churn.

Big Data technologies and the emergence of a range of predictive algorithms including Deep Learning \citep{LeCun:2015} have meant that systems for churn analysis should be part of the repertoire for Software Architects to advise on.

This paper provides a illustrative comparison of some methods that use deep learning for customer churn, particularly but not exclusively in the SaaS product industry. There are other churn prediction methods used that aren't based on deep learning such as \citep{Backiel:2016}, which for no-contract customers of a mobile network finds that using social network information can improve the accuracy of churn prediction. 

Included as part of this article are summaries of three state-of-the-art existing methods to predict churn using deep learning methods. The study also provides suggestions for improvement of churn prediction.

\subsection{Motivation}
Most enterprise application have moved or are likely to soon move from a traditional model to a subscription based model such as in \citep{Pettey:2015} and one result of this is the focus on ensuring customers renew their software subscription. Firms are adopting Big Data techniques as part of business strategy \citep{HBR:2017} to gather historical operational data in order to gain more awareness of the behaviors of their customers in an effort to better serve them. Businesses want to also make predictions \citep{Hausman:2017} to be able to identify their most profitable customer segments, forecast sales/revenue, enable demand based pricing and to improve customer satisfaction so customers stay being their customers. 

In recent years, there have been successful advancements in the application of ANNs and in particular multi-layer ANNs called Deep Learning models to the analysis of large datasets. Of particular note is the successful use of RNNs \citep{Karpathy:2015} as an effective predictive model to deal with time-series data such as customer behavior information.

\section{Literature Review}
I have investigated in detail several articles on churn or customer lifetime value prediction. I have summarized three of them in this section.

\cite{Martinsson:2016} has suggested that the correct way to model for churn is to think of it in a similar way to how engineers try to predict engine failure or insurance actuaries predict how long a person has left to live. He identifies survival analysis as the mathematically simple technique to predict customer churn. These statistical methods, which are typically used in medicine and engineering, are a good match for when you are interested in understanding how long something (customers, engines, human hearts) survives and the actions that can help it survive for longer. Survival analysis methods handle censored data, which means that if some of the observations in the data weren't available for the time period needed e.g. if you want to look at a year of churn for customers but some of them have only been signed up for a couple of months. Using survival analysis censored data he was able to avoid the typical sliding time window scenario where only the most recent data is factored into a prediction. The model employed accommodates the use of all available data to estimate how many observations are still 'surviving' at that time. 

Rather than predict churn he suggests to predict non-churn. If some event happens in the future that we're able to use to define the customer as non-churned and we're able to predict the time of that event then the further away that event is we can say the more churned that customer will be. Each customer would have a set of data that contains events (used to define churn) e.g. login or purchases and features. Then the work is to predict the time to the next event for a given customer. Those customers where there is a longer wait until they are churned are seen as being more churned. The goal is to predict what customers have churned more than others. He employs a solid definition of what churn means, i.e. the customer isn't returning rather than the customer is currently inactive, and then chooses a RNN as the model to predict events based on patterns in the previous data. The event that predicts non-churn could be a purchases or logins whatever matters for churn definition.

He designs a model that looks at the timeline of past features leading up to the present and then predicts a distribution to describe how likely a particular event, such as churn, will happen as we look into the future. The model predicts a distribution weighted close to the present for situations where an event is likely and predicts a broader distribution for those that are unlikely to experience an event soon. There are two parameters, alpha and beta that control the shape of the distribution of the time-to-event data. He uses a recurrent neural network to ingest the past data and output alpha and beta values to obtain the distribution that shows the probability of an event occurring for a given sample. 

The data he uses in his paper is “Turbofan Engine Degradation Simulation Data Set”, an uncensored dataset from NASA where all of the engines in the data set were followed until the end of their useful life. This data was shown to be analogous to the SaaS customer churn 'failure' event. The alpha and beta parameters in the output describe a Weibull distribution showing the probability for each engine to fail over future time. For the analysis the model chose many engines as being close to failure when they really are and ones that are doing fine that really are doing fine. 

\cite{Spanoudes:2017} applies deep learning to the problem of churn prediction. In this paper they use generated abstract feature vectors to assist in the prediction of churn. Currently the company is using the machine learning algorithm Random Forest for data classification, which has increased performance when there are increased features present in the data. Random Forest algorithm avoids overfitting but they still do not perform as well on datasets where there is extreme class imbalance, for example churn prediction datasets. For the experiments churn is defined as no customer usage of the product within 30 day sequence since the companies had monthly SaaS subscriptions. Improvements are achievable with Improved Balanced Forests. That solves this problem but it still requires a manual feature engineering stage. This means a high effort is made to generate secondary features for a specific company on which the churn prediction model is applied. It's well known however that by adding more features then explaining the reasoning around the results becomes more difficult (curse of dimensionality). The feature engineering work is is a struggle and high effort to carry out.

Exploration of the emerging advances in machine learning has identified Deep Learning models as excellent tools in pattern recognition. The prediction of customer churn is carried out by doing analysis of the behavior of customers and users in order to identify patterns in the data. This technique is also seen as a candidate to eliminate the high manual effort work of feature engineering that is currently being undertaken. In this paper they create a generic data representation that can be applied to different client projects and to choose an appropriate Deep Learning architecture for unsupervised learning to be able to automatically classify patterns in the data.

The architecture proposed in this paper consists of a feedforward neural network with four layers and acts as a binary classifier to output customer who will churn and will not churn. This architecture was chosen since at the time of the research the only published paper on deep learning prediction for customer churn \cite{Castanedo:2015} used this type of model. Improvements to this architecture were added after analysis revealed the use of Dropout could allow for better generalizations and rectified linear activation functions allows for better backpropagation gradient estimations and performance. The stated goal here of using unsupervised deep learning was to find the patterns to predict churn to a higher performance of the existing model and without the need for the current engineering step.

Their tests have shown that the deep model was able to generate features using the hidden layers that are necessary for classification. They were able to increase their prediction accuracy from 73.2\% to 77.9\% so their conclusion was the multi-layer feedforward neural network was effective in churn prediction. Note that this solution doesn't apply to non-subscription companies.

The results showed that a deep learning model was more effective overall than their current model for subscription based businesses (not for non-subscription based businesses) in predicting churn. It was also able to find the relevant patterns in the data without being manually given them. During analysis increasing the hidden layers of the neural network increased the effectiveness in distinguishing between churners and non-churners. However, the new model is susceptible to performance problems with low amounts of data or data containing low churn rates. This would need further analysis.

\cite{Ljungehed:2017} created a model to see when customer begin to become less loyal, a more dynamic definition of churn. He focused on customer lifetime value which is the monetary value of a customer relationship. Customer lifetime value is used in marketing to describe the future monetary value of a customer in both spend and business promotion to other companies. In subscription based businesses defining churn is independent of the customer, it's usually related to product usage and product purchasing. In retail, customers exhibit a range of different behaviors so each customer would need a different definition of churn. The data in retail is their transaction history and there is no subscription. This paper uses customer lifetime value as an indicator of churn since it's calculated individually for each customer. He says that no change in the customer lifetime value means decrease in customer loyalty. He uses a simple model for customer lifetime value, which is the sum of transactions (with discounted rate) over time. The research uses an RNN on customer lifetime value time series regression. The identification of the key drivers of churn is also an important aspect to resolve but can be difficult to understand this information due to the black-box nature of neural networks so a K-means algorithm is employed for customer segmentation labeling such as 'high-spenders'. 

He says that there are established models to predict churn but the use of RNN is a largely unexplored approach. The advantages if an RNN in this problem is that they are robust to temporal noise and are suitable for sequential data. The focus of the paper explores using an RNN for predicting churn based on customer lifetime value (CLV) time series. 

An RNN is like using a simple (feedforward) neural network except that it contains loops of to allow information to passed from one timestep to the next causing retention of memory. These ANNs were known to be difficult to train until some breakthroughs such as the long short-term memory recurrent neural network (RNN) or LSTM. The prediction model is to use RNNs with time-series CLV data. The anonymized data was collected by a retail company through its customer loyalty program and it contained purchase (online or in-person) and demographic history for each member. Over two million members data spanning three years were included making up tens of millions of transactions. The data was cleansed of outliers (e.g. no members who completed less than 6 purchases) and pre-clustered using K-means before being used to train the RNN to obtain the churn prediction.

The model was used to predict the customer lifetime value for each customer every 30 days for for 180 days into the future. There were 10 clusters of members created. The combination of the clustering and the churn prediction were demonstrated to have been able to identify the different trends of the members. Issues occurred where the dominance in a cluster of one group (churners or non-churners) overshadowed the other group and so skewed the predictions. Overall the RNN model outperformed random and discovered the correct trends so its a technique with a promising approach to churn prediction.

\subsection{Contribution}
In this section I offer any insights and additional work that could lead to improved results.

\cite{Martinsson:2016} used a dataset from NASA on engines and it would be interesting to apply his model to web event or customer churn data sets. He also used vanilla RNNs so it would be interesting to explore adjustments in the neural network architecture to understand if adjusting the parameters of the network affected the accuracy of prediction.

\cite{Spanoudes:2017} did his analysis on a quite simple neural network model, a multi-layer feedforward with backpropagation employing Dropout. The researcher was not an expert in deep neural networks.  An proven option to use in this type of time series prediction is a RNN so repeating the analysis with this type of model to see if there is an improvement could yield some addition useful results.

\cite{Ljungehed:2017} used one RNN, LSTM, and only one way to segment his data, K-means. He didn't spend time optimizing his network parameters so there are a few avenues to investigate increased performance in his work by experimenting with the parameters. One limiter of his work was that he used a limited setup AWS server with 16GB RAM and hit some performance limitations with RAM usage and the JDBC driver. Specific training for the model on trend groups to avoid a situation where the dominant group in a cluster leads to poor model performance. Instead of using K-means he could have used a recurrent neural network to do clustering.

\cite{Backiel:2016} suggests that if social network analysis was combined with other operational information it may lead to an improvement in churn prediction.

\cite{Liao:2016} proposed using an stacked model using LSTM, K-means and Weibull survival analysis to predict failure of trucks in a mining business since a day of truck downtime costs US\$1.5M the mine. The study mentioned there is little guidance to choose the parameters of the deep learning model so trial and error was chosen instead. Of interest was their use of an open-source dataset of hard drive reliability. The results showed the deep model performed much higher than a traditional Cox Proportional Hazard model. An interesting endeavour would be to test this deep model with different network configuration parameters.

\cite{Katzman:2016} successfully used a deep feedforward neural network based model called DeepServ with survival analysis on human patients to advice on treatments. The paper advises on a way to generate test data useful for this type of study. The study reported that "DeepSurv has the potential to supplement traditional survival analysis methods and become a standard method for medical practitioners to study and recommend personalized treatment options". A new avenue to explore is to use a RNN as part of DeepServ on the data to check for increased performance of treatment recommendation.

\cite{Chamberlain:2017} describes an feedforward neural network customer lifetime value prediction model for an on-line clothes retailer that replaces a Random Forest based model with a human bottleneck that requires large numbers of handcrafted features. Repeating the work but using an RNN would be a worth-while exercise.

An interesting area of study would be to see if Deep Learning based models can more generally replace current Random Forest based models for customer lifetime value prediction.




\section{Conclusion}
I conclude that further study is needed to find optimal setups for churn prediction models. Use of RNNs and Survival analysis look promisning. Investigation of using different paramenters for network setup would prove useful.


% use section* for acknowledgement
\section*{Acknowledgment}
The author would like to thank Penny O'Hara for the cups of tea and for keeping our children Naomi and Eve busy during the writing of this paper.


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi


%
\medskip




\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}
\bibliographystyle{agsm}
\begin{thebibliography}{99} % Bibliography - this is intentionally simple in this template

\bibitem[LeCun et al, 2015]{LeCun:2015}LeCun, Y., Bengio, Y. and Hinton, G. (2015). 
\newblock Deep learning. Nature, 521(7553), pp.436-444.

\bibitem[Karpathy, 2015]{Karpathy:2015} Karpathy, A., 2015. The unreasonable effectiveness of recurrent neural networks. Andrej Karpathy blog. [online] Available at: http://karpathy.github.io/2015/05/21/rnn\-effectiveness/ [Accessed 13 Nov. 2017].

\bibitem[Castanedo et al, 2015]{Castanedo:2015} Castanedo, F., Valverde, G., Zaratiegui, J. and Vazquez, A., 2014. Using deep learning to predict customer churn in a mobile telecommunication network.

\bibitem[Pettey, 2015]{Pettey:2015} Pettey, C. (2015). Moving to a Software Subscription Model. [online] Smarter With Gartner. Available at: https://www.gartner.com/smarterwithgartner/moving-to-a-software-subscription-model/ [Accessed 10 Nov. 2017].

\bibitem[Backiel et al, 2016]{Backiel:2016} Backiel, A., Baesens, B. and Claeskens, G., 2016. Predicting time-to-churn of prepaid mobile telephone customers using social network analysis. Journal of the Operational Research Society, 67(9), p.0.

\bibitem[Martinsson, 2016]{Martinsson:2016}
Egil Martinsson (2016).
\newblock WTTE-RNN : Weibull Time To Event Recurrent Neural Network. A model for sequential prediction of time-to-event in the case of discrete or continuous censored data, recurrent events or time-varying covariates. Available at: https://ragulpr.github.io/assets/
draft\_master\_thesis\_martinsson\_egil\_wtte\_rnn\_2016.pdf  [Accessed 10 Nov. 2017].

\bibitem[Liao et al, 2016]{Liao:2016} Liao, L. and Ahn, H.I., 2016. Combining Deep Learning and Survival Analysis for Asset Health Management. International Journal of Prognostics and Health Management.

\bibitem[Katzman et al, 2016]{Katzman:2016} Katzman, J., Shaham, U., Bates, J., Cloninger, A., Jiang, T. and Kluger, Y., 2016. Deep survival: A deep cox proportional hazards network. arXiv preprint arXiv:1606.00931.

\bibitem[Chamberlain et al, 2017]{Chamberlain:2017} Chamberlain, B.P., Cardoso, A., Liu, C.H., Pagliari, R. and Deisenroth, M.P., 2017. Customer Life Time Value Prediction Using Embeddings. arXiv preprint arXiv:1703.02596.

\bibitem[Spanoudes et al, 2017]{Spanoudes:2017} Spanoudes, P. and Nguyen, T., 2017. Deep Learning in Customer Churn Prediction: Unsupervised Feature Learning on Abstract Company Independent Feature Vectors. arXiv preprint arXiv:1703.03869.

\bibitem[Ljungehed, 2017]{Ljungehed:2017} Ljungehed, J. (2017). Predicting Customer Churn Using Recurrent Neural Networks. [online] www.nada.kth.se. Available at: http://www.nada.kth.se/\~ann/exjobb/jesper\_ljungehed.pdf [Accessed 10 Nov. 2017].

\bibitem[HBR, 2017]{HBR:2017}Harvard Business Review. (2017). How Companies Say They’re Using Big Data. [online] Available at: https://hbr.org/2017/04/how-companies-say-theyre-using-big-data [Accessed 10 Nov. 2017].

\bibitem[Hausman, 2017]{Hausman:2017} Angela Hausman, P. (2017). Predictive Analytics: Predicting Customer Behavior to Improve ROI. [online] Business 2 Community. Available at: https://www.business2community.com/big\-data/predictive\-analytics\-predicting\-customer\-behavior\-improve\-roi\-01915285\#E0ePfbUpyXE1R9KA.97 [Accessed 10 Nov. 2017].

\end{thebibliography}

% that's all folks
\end{document}


